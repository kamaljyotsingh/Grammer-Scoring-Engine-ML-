{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":11283469,"sourceType":"datasetVersion","datasetId":7054703}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d7eb9647-e356-43b5-a995-fa1dc102c6fa","cell_type":"markdown","source":"# Grammar Scoring Engine using Whisper + Rule-based Features\n\n### 1. Introduction\n\nIn this project, we develop a Grammar Scoring Engine for spoken English using audio files. The task is part of a Kaggle competition where each input is a WAV file (45-60s) and the output is a grammar score between 0 and 5 (continuous). \n\nWe utilize OpenAI's Whisper model to transcribe the audio, followed by lightweight rule-based grammar feature extraction (like POS tagging) using `nltk`. A Random Forest Regressor is then trained on these features.","metadata":{}},{"id":"70f17e30-c121-417b-a1d2-ed8bf28c0d02","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/shl-dataset'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d96b322c-1bc2-4955-8142-1162ae0ea196","cell_type":"code","source":"!pip install -q openai-whisper\n!pip install -q nltk scikit-learn pandas tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"37f16250-3da5-4ab2-9586-29d7fc28099f","cell_type":"code","source":"import os\nimport whisper\nimport pandas as pd\nimport nltk\nfrom nltk import word_tokenize, pos_tag\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm\n\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\n\nmodel = whisper.load_model(\"base\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"516c374a-0a54-474b-b34c-557f72c5c83a","cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/shl-dataset/dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/shl-dataset/dataset/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/shl-dataset/dataset/sample_submission.csv\")\ntrain_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"027dc660-fda9-49c1-97e5-ae8f0df98083","cell_type":"code","source":"def extract_features(audio_path):\n    result = model.transcribe(audio_path, fp16=False)\n    text = result['text'].strip()\n    \n    tokens = word_tokenize(text)\n    pos_tags = pos_tag(tokens)\n\n    total_words = len(tokens)\n    num_nouns = sum(1 for word, tag in pos_tags if tag.startswith('NN'))\n    num_verbs = sum(1 for word, tag in pos_tags if tag.startswith('VB'))\n    num_adjs = sum(1 for word, tag in pos_tags if tag.startswith('JJ'))\n    avg_word_len = sum(len(word) for word in tokens) / total_words if total_words else 0\n\n    return {\n        'text': text,\n        'total_words': total_words,\n        'num_nouns': num_nouns,\n        'num_verbs': num_verbs,\n        'num_adjs': num_adjs,\n        'avg_word_len': avg_word_len\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bc86c3b3-ee59-4f77-9187-4e37f611ba55","cell_type":"code","source":"print(len(train_features))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"82964290-c928-4e98-b967-2dadaddf68db","cell_type":"code","source":"train_features = []\n\nfor i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n    audio_filename = row['filename']\n    audio_path = f\"/kaggle/input/shl-dataset/dataset/audios_train/{audio_filename}\"  # ✅ FULL PATH TO FILE\n\n    try:\n        features = extract_features(audio_path)  # Pass full path\n        features['label'] = row['label']\n        train_features.append(features)\n    except Exception as e:\n        print(f\"❌ Failed to process {audio_filename}: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9713cdf1-6779-4093-94c8-9f52bea6e9de","cell_type":"code","source":"X = train_feat_df[['total_words', 'num_nouns', 'num_verbs', 'num_adjs', 'avg_word_len']]\ny = train_feat_df['label']\n\nmodel_rf = RandomForestRegressor(random_state=42)\nmodel_rf.fit(X, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1ee66f26-c837-46bb-9306-3dc54620aeaf","cell_type":"code","source":"y_pred = model_rf.predict(X)\nmse = mean_squared_error(y, y_pred)\nprint(f\"Train MSE: {mse:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9820034-b71b-4e6a-bba7-26d69b853401","cell_type":"code","source":"test_features = []\n\nfor i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    path = f\"/mnt/data/audios_test{row['file'].split('test')[-1]}\"\n    features = extract_features(path)\n    test_features.append(features)\n\ntest_feat_df = pd.DataFrame(test_features)\nX_test = test_feat_df[['total_words', 'num_nouns', 'num_verbs', 'num_adjs', 'avg_word_len']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"55688776-9b20-4073-923e-e30ffb9cc656","cell_type":"code","source":"preds = model_rf.predict(X_test)\nsubmission = pd.DataFrame({'file': test_df['file'], 'label': preds})\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"267a1382-ff04-4782-aa4f-c65d7f371104","cell_type":"markdown","source":"### 10. Conclusion\n\nWe developed a simple, fast, and efficient Grammar Scoring Engine using Whisper transcription and basic rule-based features from the transcript. The model performs reasonably well on train data and can be improved further by:\n\n- Using more linguistic features like grammatical errors, parse trees, etc.\n- Incorporating BERT embeddings or transformer-based text models\n- Fine-tuning Whisper to your data\n- Using end-to-end audio-to-score models\n\nThis serves as a great baseline to build upon for the final Kaggle submission.","metadata":{}}]}